{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:10.586099Z",
     "end_time": "2023-04-07T12:26:15.118991Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "@Author   :   Corley Tang\n",
    "@contact  :   cutercorleytd@gmail.com\n",
    "@Github   :   https://github.com/corleytd\n",
    "@Time     :   2023-01-19 23:11\n",
    "@Project  :   Hands-on Deep Learning with PyTorch-learning_of_neural_network\n",
    "神经网络的学习\n",
    "'''\n",
    "\n",
    "# 导入所需的库\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ipywidgets import interact, fixed\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer as LBC\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到了损失函数之后，就需要求出损失函数最小时对应的权重向量w，复杂模型的参数较多，需要使用迭代算法来逼近最小值。\n",
    "## 1.深入认识梯度下降\n",
    "![loss_func_demo](../assets/loss_func_demo.png)\n",
    "\n",
    "梯度下降开始时，会随机设定初始权重，并从起始点开始，让w沿着损失减小最快的方向移动，每步的方向就是当前位置对应的梯度向量的反方向，每步的距离就是步长 * 当前位置所对应的梯度向量的大小（也就是梯度向量的模长），梯度向量的性质保证了沿着其反方向、按照其大小进行移动，就能够接近损失函数的最小值。\n",
    "### 找出梯度向量的方向和大小\n",
    "梯度向量是多元函数上，各个自变量的偏导数组成的向量，梯度向量中的具体元素就是各个自变量的偏导数，这些偏导数的具体值必须依赖于当前所在坐标点的值进行计算：\n",
    "(1)梯度的大小和方向对每个坐标点而言是独一无二的，坐标点一旦变化，梯度向量的方向和大小也会变化；\n",
    "(2)每走到一个新的点，将该点的坐标带入梯度向量的表达式进行计算，就可以得到当前点对应的梯度向量的方向和大小。\n",
    "### 让坐标点移动起来（进行一次迭代）\n",
    "权重向量的迭代公式：\n",
    "$$\\boldsymbol{w}_{(t+1)}=\\boldsymbol{w}_{(t)}-\\eta \\frac{\\partial L}{\\partial \\boldsymbol{w}_{(t)}}$$\n",
    "\n",
    "从公式中可以看到，偏导数的大小影响整体梯度向量的大小，偏导数前的剪号影响整体梯度向量的方向。使用一个式子，就同时控制了大小和方向，可见**大道至简**。\n",
    "一旦迭代 ，损失函数也会发生变化，可视化如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:15.124993Z",
     "end_time": "2023-04-07T12:26:15.131991Z"
    }
   },
   "outputs": [],
   "source": [
    "w1 = np.arange(-5, 15, 0.05)\n",
    "w2 = np.arange(-10, 10, 0.05)\n",
    "w1, w2 = np.meshgrid(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:15.141995Z",
     "end_time": "2023-04-07T12:26:16.424760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(Dropdown(description='elev', options=(0, 15, 30), value=0), IntSlider(value=60, descript…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efc13c217c1c43cf9abc42275972f341"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义绘制三维图像的函数\n",
    "def plot_3d(elev=45, azim=60, x=w1, y=w2):\n",
    "    '''\n",
    "    绘制三维图像\n",
    "    :param elev: 上下旋转的角度\n",
    "    :param azim: 水平旋转的角度\n",
    "    :param x: x轴\n",
    "    :param y: y轴\n",
    "    :param z: z轴\n",
    "    :return: None\n",
    "    '''\n",
    "    sse = (3 - x - y) ** 2 + (6 - 2 * x - y) ** 2  # 损失函数\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.plot_surface(x, y, sse, cmap='rainbow', alpha=0.7)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('w1', fontsize=10)\n",
    "    ax.set_ylabel('', fontsize=10)\n",
    "    ax.set_zlabel(\"sse\", fontsize=10)\n",
    "\n",
    "\n",
    "# 调用\n",
    "interact(plot_3d, elev=[0, 15, 30], azim=(-180, 180), x=fixed(w1), y=fixed(w2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.找出距离和方向——反向传播\n",
    "### 初步认识反向传播\n",
    "在进行梯度下降时，需要得到当前位置的梯度向量，过程中最大的难点就在于获得梯度向量的表达式。一个2层的二分类神经网络的的梯度（导数）计算过程如下：\n",
    "![2_layer_grad_compute](../assets/2_layer_grad_compute.png)\n",
    "\n",
    "可以看到，对$w^{(1 \\rightarrow 2)}$和$w^{(0 \\rightarrow 1)}$的求导过程很长、很复杂，此时需要利用链式法则对复杂网络求导过程进行简单化：\n",
    "$$\\frac{\\partial u}{\\partial w}=\\frac{\\partial u}{\\partial z} * \\frac{\\partial z}{\\partial w}$$\n",
    "\n",
    "其中， 函数u=h(z)、z=f(w)，且两个函数在各自自变量的定义域上都可导。\n",
    "对链式法则的感性认识：当一个函数是由多个函数嵌套而成，最外层函数向最内层自变量求导的值，等于外层函数对外层自变量求导的值与内层函数对内层自变量求导的值的乘积。\n",
    "使用链式法则求解梯度：\n",
    "$$\\frac{\\partial \\text { Loss }}{\\partial w^{(1 \\rightarrow 2)}} =\\sigma^{(1)}\\left(\\sigma^{(2)}-y\\right) \\\\\n",
    "\\frac{\\partial \\text { Loss }}{\\partial w^{(0 \\rightarrow 1)}}=\\left(\\sigma^{(2)}-y\\right) * w^{1 \\rightarrow 2} *\\left(\\sigma^{(1)}\\left(1-\\sigma^{(1)}\\right)\\right) * X$$\n",
    "\n",
    "可以看到，计算出来的表达式非常简单，同时所有的变量都是在正向传播中已经计算好或输入模型的变量。求解导数时是从左向右、从输出向输入，逐渐往前，并且所使用的节点上的张量，也是从后向前逐渐用到，这和我们正向传播的过程完全相反，这种从左到右、不断使用正向传播中的元素对梯度向量进行计算的方式，就是**反向传播**。\n",
    "### PyTorch实现反向传播\n",
    "在梯度下降中，每走一步都需要更新梯度，计算量巨大，PyTorch已经实现了自动计算梯度，有两种方式实现梯度计算：\n",
    "- autograd.grad()：使用torch.autograd.grad()函数计算出损失函数上具体某个点/某个变量的导数，适用于单层神经网络\n",
    "- backward()：对于深层神经网络，需要一次性计算大量权重对应的导数值，并且这些权重是以层为单位组织成权重矩阵，可以直接使用PyTorch提供的基于autograd的反向传播功能损失的backward()方法来进行计算\n",
    "    需要注意，在实现反向传播之前，首先要完成模型的正向传播，并且要定义损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.431760Z",
     "end_time": "2023-04-07T12:26:16.507755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(4.),)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.AutoGrad计算梯度\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x ** 2\n",
    "torch.autograd.grad(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.507755Z",
     "end_time": "2023-04-07T12:26:16.534963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(5.9598),)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randint(2, size=(1,))\n",
    "z = x ** 2 + 2 * x - 3\n",
    "sigma = z.sigmoid()\n",
    "loss = -(y * sigma.log() + (1 - y) * (1 - sigma).log())\n",
    "torch.autograd.grad(loss, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.539963Z",
     "end_time": "2023-04-07T12:26:16.550965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([500, 20]), torch.Size([500]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造数据\n",
    "X = torch.randn((500, 20)) * 100\n",
    "y = torch.randint(3, size=(500,))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.556963Z",
     "end_time": "2023-04-07T12:26:16.586960Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.backward()\n",
    "# 定义模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=10, out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, 13, bias=False)\n",
    "        self.linear2 = nn.Linear(13, 8, bias=False)\n",
    "        self.output = nn.Linear(8, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        z_hat = self.output(sigma2)\n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.572962Z",
     "end_time": "2023-04-07T12:26:16.597963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (linear1): Linear(in_features=20, out_features=13, bias=False)\n  (linear2): Linear(in_features=13, out_features=8, bias=False)\n  (output): Linear(in_features=8, out_features=3, bias=False)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化模型\n",
    "input_dim = X.shape[1]\n",
    "output_dim = y.unique().sum().int().item()\n",
    "model = Model(input_dim, output_dim)\n",
    "model  # 输出模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.600963Z",
     "end_time": "2023-04-07T12:26:16.642336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([500, 3])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前向传播\n",
    "z_hat = model(X)\n",
    "z_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.625326Z",
     "end_time": "2023-04-07T12:26:16.647339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.1353, grad_fn=<NllLossBackward0>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(z_hat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.647339Z",
     "end_time": "2023-04-07T12:26:16.662338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.0049,  0.0229, -0.0828,  0.1596,  0.0724,  0.0471,  0.1874,  0.0747,\n          0.0457,  0.2163,  0.0612, -0.0009,  0.0977, -0.0329, -0.2020, -0.1641,\n          0.2143,  0.0130, -0.0695, -0.0362], grad_fn=<SelectBackward0>),\n None)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看权重和梯度\n",
    "model.linear1.weight[0], model.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.666340Z",
     "end_time": "2023-04-07T12:26:16.702334Z"
    }
   },
   "outputs": [],
   "source": [
    "# 反向传播、计算梯度\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.679339Z",
     "end_time": "2023-04-07T12:26:16.723340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.0049,  0.0229, -0.0828,  0.1596,  0.0724,  0.0471,  0.1874,  0.0747,\n          0.0457,  0.2163,  0.0612, -0.0009,  0.0977, -0.0329, -0.2020, -0.1641,\n          0.2143,  0.0130, -0.0695, -0.0362], grad_fn=<SelectBackward0>),\n tensor([-4.0165e-03,  1.2522e-02, -1.2325e-02, -1.0145e-02, -9.9331e-03,\n         -2.0769e-02,  1.5413e-04,  2.6265e-02, -1.7333e-02, -4.4034e-03,\n          5.6439e-03,  2.5885e-03,  2.5273e-02, -8.9707e-03,  1.1992e-02,\n          1.9955e-02,  2.6359e-03,  4.3577e-05,  9.2752e-03,  9.0639e-03]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新查看，权重未更新、梯度更新\n",
    "model.linear1.weight[0], model.linear1.weight.grad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.715337Z",
     "end_time": "2023-04-07T12:26:16.746146Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss.backward()：RuntimeError，不能重复执行，要想重复执行，需指定retain_graph参数为True用于保存计算图，只能有效保存一次\n",
    "z_hat = model(X)\n",
    "loss = criterion(z_hat, y)\n",
    "loss.backward(retain_graph=True)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用autograd的时候，定义张量需要指定requires_grad参数为True，但在定义打包好的类以及使用loss.backward()的时候，却\n",
    "没有给任何数据定义requires_grad=True，这是因为：\n",
    "- 当使用nn.Module继承后的类进行正向传播时，权重w是自动生成的，在生成时就被自动设置为允许计算梯度（requires_grad=True），所以不需要手动去设置。\n",
    "- 特征张量X与真实标签y都不在反向传播的过程当中，但是它们都是损失函数计算需要用的值，backward函数是通过下面的方式判断哪些张量需要求解梯度：首先backward值会识别叶子节点，不在叶子上的变量是不会被backward考虑的；对于全部叶子节点来说，只有属性requires_grad=True的节点，才会被计算。因此在设置X与y时，没有设置requires_grad参数，默认让“允许求解梯度”为False，所以backward在计算的时候就只会计算关于权重w的部分。\n",
    "\n",
    "## 3.移动坐标点——Optim\n",
    "### 走出第一步\n",
    "根据反向传播得到了梯度向量，就有了大小和方向，接下来我们就可以开始走出第一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.731343Z",
     "end_time": "2023-04-07T12:26:16.766148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.0049,  0.0229, -0.0828,  0.1596,  0.0724,  0.0471,  0.1874,  0.0747,\n          0.0457,  0.2163,  0.0612, -0.0009,  0.0977, -0.0329, -0.2020, -0.1641,\n          0.2143,  0.0130, -0.0695, -0.0362]),\n tensor([-0.0120,  0.0376, -0.0370, -0.0304, -0.0298, -0.0623,  0.0005,  0.0788,\n         -0.0520, -0.0132,  0.0169,  0.0078,  0.0758, -0.0269,  0.0360,  0.0599,\n          0.0079,  0.0001,  0.0278,  0.0272]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 5  # 步长，即学习率，一般小于1\n",
    "w = model.linear1.weight.data  # 当前的权重\n",
    "dw = model.linear1.weight.grad  # 当前的梯度\n",
    "w[0], dw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.761151Z",
     "end_time": "2023-04-07T12:26:16.817150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 0.0554, -0.1649,  0.1020,  0.3117,  0.2214,  0.3586,  0.1851, -0.3193,\n          0.3057,  0.2824, -0.0234, -0.0398, -0.2813,  0.1016, -0.3819, -0.4634,\n          0.1747,  0.0124, -0.2086, -0.1721]),\n tensor([-0.0120,  0.0376, -0.0370, -0.0304, -0.0298, -0.0623,  0.0005,  0.0788,\n         -0.0520, -0.0132,  0.0169,  0.0078,  0.0758, -0.0269,  0.0360,  0.0599,\n          0.0079,  0.0001,  0.0278,  0.0272]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w(t+1) = w(t) - α * grad\n",
    "# 更新第1次\n",
    "w -= lr * dw\n",
    "w[0], dw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.790151Z",
     "end_time": "2023-04-07T12:26:16.821151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 0.1156, -0.3528,  0.2869,  0.4639,  0.3704,  0.6701,  0.1828, -0.7133,\n          0.5657,  0.3484, -0.1081, -0.0786, -0.6604,  0.2362, -0.5618, -0.7628,\n          0.1352,  0.0117, -0.3478, -0.3081]),\n tensor([-0.0120,  0.0376, -0.0370, -0.0304, -0.0298, -0.0623,  0.0005,  0.0788,\n         -0.0520, -0.0132,  0.0169,  0.0078,  0.0758, -0.0269,  0.0360,  0.0599,\n          0.0079,  0.0001,  0.0278,  0.0272]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新第2次，实际上不能这么操作，因为权重与梯度是同步更新的\n",
    "w -= lr * dw\n",
    "w[0], dw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.825154Z",
     "end_time": "2023-04-07T12:26:16.901012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([ 0.1168, -0.3565,  0.2906,  0.4670,  0.3734,  0.6763,  0.1827, -0.7211,\n          0.5709,  0.3498, -0.1098, -0.0794, -0.6680,  0.2389, -0.5654, -0.7687,\n          0.1344,  0.0117, -0.3505, -0.3108]),\n tensor([-0.0120,  0.0376, -0.0370, -0.0304, -0.0298, -0.0623,  0.0005,  0.0788,\n         -0.0520, -0.0132,  0.0169,  0.0078,  0.0758, -0.0269,  0.0360,  0.0599,\n          0.0079,  0.0001,  0.0278,  0.0272]))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新第3次\n",
    "lr = 0.1\n",
    "w -= lr * dw\n",
    "w[0], dw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从第一步到第二步：动量法Momentum\n",
    "普通梯度下降就是在重复正向传播、计算梯度、更新权重的过程，但这个过程往往非常漫长，学习率设置得特别小时会更漫长，只有当学习率设置得非常巨大，才能够看到一些改变，但巨大的学习率可能会跳过真正的最小值，所以无法将步长设置得很大，无论如何，梯度下降都是一个缓慢的过程。此时可以通过使用动量Momentum来加速迭代。动力图示如下：\n",
    "![momentum_demo](../assets/momentum_demo.png)\n",
    "\n",
    "其中，对上一步的梯度向量加上的权重被称为动量参数（也叫做衰减力度，通常使用γ进行表示），对这一点的梯度向量加上的权重就是步长（依然表示为η），真实移动的向量为$v_t$，即称为动量（Momentum）。对应公式如下：\n",
    "$$\\begin{aligned}\n",
    "v_{(t)} & =\\gamma v_{(t-1)}-\\eta \\frac{L}{\\partial \\boldsymbol{w}} \\\\\n",
    "\\boldsymbol{w}_{(t+\\mathbf{1})} & =\\boldsymbol{w}_{(t)}+v_{(t)}\n",
    "\\end{aligned}$$\n",
    "\n",
    "此时$v{t-1}$代表了之前所有步骤所累积的动量和，梯度下降的方向有了“惯性”，受到历史累计动量的影响：当新坐标点的梯度反方向与历史累计动量的方向一致时，历史累计动量会加大实际方向的步子；当新坐标点的梯度反方向与历史累计动量的方向不一致时，历史累计动量会减小实际方向的步子。\n",
    "### 动量法的手动实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.857014Z",
     "end_time": "2023-04-07T12:26:16.902012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([13, 20]), torch.Size([13, 20]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "w = model.linear1.weight.data  # 当前的权重\n",
    "dw = model.linear1.weight.grad  # 当前的梯度\n",
    "w.shape, dw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.887012Z",
     "end_time": "2023-04-07T12:26:16.918015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.1180, -0.3603,  0.2943,  0.4700,  0.3764,  0.6826,  0.1827, -0.7290,\n         0.5761,  0.3511, -0.1115, -0.0801, -0.6756,  0.2416, -0.5690, -0.7747,\n         0.1336,  0.0117, -0.3533, -0.3135])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第1步\n",
    "v = torch.zeros_like(dw)  # v(0)\n",
    "v = gamma * v - lr * dw  # v(t) = gamma * v(t-1) - lr * dw\n",
    "w += v  # w(t+1) = w(t) + v(t)\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.920029Z",
     "end_time": "2023-04-07T12:26:16.986811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.1203, -0.3674,  0.3013,  0.4758,  0.3820,  0.6944,  0.1826, -0.7440,\n         0.5860,  0.3536, -0.1147, -0.0816, -0.6900,  0.2467, -0.5758, -0.7861,\n         0.1321,  0.0117, -0.3586, -0.3187])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第2步\n",
    "v = gamma * v - lr * dw\n",
    "w += v\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.952014Z",
     "end_time": "2023-04-07T12:26:16.988816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.1236, -0.3776,  0.3114,  0.4840,  0.3901,  0.7113,  0.1825, -0.7654,\n         0.6000,  0.3572, -0.1193, -0.0837, -0.7105,  0.2540, -0.5856, -0.8023,\n         0.1300,  0.0117, -0.3662, -0.3261])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第3步\n",
    "v = gamma * v - lr * dw\n",
    "w += v\n",
    "w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，加入了动量之后，权重的更新更加明显，即**动量可以加速圈中的迭代**，即使设置较小的学习率，也能看到权重的明显变化。\n",
    "### torch.optim实现带动量的梯度下降\n",
    "PyTorch库的架构中拥有专门实现优化算法的模块`torch.optim`可以实现带动量的梯度下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:16.967813Z",
     "end_time": "2023-04-07T12:26:17.021814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([500, 20]), torch.Size([500]), 0.1, 0.9)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一、准备阶段\n",
    "# 数据和超参\n",
    "X.shape, y.shape, lr, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.000812Z",
     "end_time": "2023-04-07T12:26:17.075258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(Model(\n   (linear1): Linear(in_features=20, out_features=13, bias=False)\n   (linear2): Linear(in_features=13, out_features=8, bias=False)\n   (output): Linear(in_features=8, out_features=3, bias=False)\n ),\n tensor([ 0.0055, -0.1124, -0.0330,  0.0182, -0.0995,  0.2069, -0.1641,  0.0549,\n          0.0335, -0.0938,  0.1934,  0.0222, -0.1783, -0.1355, -0.1093, -0.0061,\n          0.1832,  0.1491, -0.0114,  0.1842], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = Model(input_dim, output_dim)\n",
    "model, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.026811Z",
     "end_time": "2023-04-07T12:26:17.076259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 损失函数\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.044341Z",
     "end_time": "2023-04-07T12:26:17.088259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x000001ED3C4E6900>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义优化算法\n",
    "model.parameters()  # 获取模型所有的权重和截距，返回生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.060052Z",
     "end_time": "2023-04-07T12:26:17.090259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 20])\n",
      "torch.Size([8, 13])\n",
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# 遍历访问\n",
    "for param in model.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.100263Z",
     "end_time": "2023-04-07T12:26:17.178785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "SGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.1\n    maximize: False\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 0\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(  # 随机梯度下降\n",
    "    model.parameters(),  # 需要进行迭代的权重\n",
    "    lr=lr,  # 学习率\n",
    "    momentum=gamma  # 动量系数\n",
    ")\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.124263Z",
     "end_time": "2023-04-07T12:26:17.181782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(1.1442, grad_fn=<NllLossBackward0>),\n tensor([ 0.0040, -0.1134, -0.0330,  0.0207, -0.1004,  0.2082, -0.1644,  0.0552,\n          0.0334, -0.0936,  0.1942,  0.0221, -0.1778, -0.1380, -0.1069, -0.0057,\n          0.1837,  0.1496, -0.0116,  0.1849], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 二、梯度下降的过程——第1步\n",
    "# 1.前向传播\n",
    "z_hat = model(X)  # 最后一个线性层的输出结果\n",
    "# 2.计算损失\n",
    "loss = criterion(z_hat, y)\n",
    "# 3.反向传播、求解梯度\n",
    "loss.backward()\n",
    "# 4.更新权重（和动量）\n",
    "optimizer.step()  # 走一步，更新动量和权重\n",
    "# 5.清空梯度：清除前面计算出来的、基于当前位置计算出来的梯度，用于下一步的梯度计算\n",
    "optimizer.zero_grad()\n",
    "# 查看损失和权重\n",
    "loss, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.156039Z",
     "end_time": "2023-04-07T12:26:17.201783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(1.1299, grad_fn=<NllLossBackward0>),\n tensor([ 0.0012, -0.1148, -0.0335,  0.0253, -0.1024,  0.2110, -0.1644,  0.0556,\n          0.0329, -0.0934,  0.1954,  0.0222, -0.1776, -0.1417, -0.1028, -0.0045,\n          0.1843,  0.1503, -0.0109,  0.1856], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三、第2步\n",
    "z_hat = model(X)\n",
    "loss = criterion(z_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "loss, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.183786Z",
     "end_time": "2023-04-07T12:26:17.253278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(1.1121, grad_fn=<NllLossBackward0>),\n tensor([-0.0043, -0.1164, -0.0354,  0.0341, -0.1063,  0.2171, -0.1632,  0.0548,\n          0.0310, -0.0935,  0.1965,  0.0227, -0.1785, -0.1476, -0.0951, -0.0016,\n          0.1845,  0.1511, -0.0084,  0.1864], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 四、第3步\n",
    "z_hat = model(X)\n",
    "loss = criterion(z_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "loss, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.220281Z",
     "end_time": "2023-04-07T12:26:17.255276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(1.0973, grad_fn=<NllLossBackward0>),\n tensor([-0.0126, -0.1184, -0.0392,  0.0482, -0.1120,  0.2276, -0.1603,  0.0518,\n          0.0277, -0.0944,  0.1969,  0.0230, -0.1806, -0.1560, -0.0820,  0.0045,\n          0.1829,  0.1516, -0.0033,  0.1871], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 五、第4步\n",
    "z_hat = model(X)\n",
    "loss = criterion(z_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "loss, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.248277Z",
     "end_time": "2023-04-07T12:26:17.339331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(1.0908, grad_fn=<NllLossBackward0>),\n tensor([-0.0237, -0.1208, -0.0453,  0.0670, -0.1191,  0.2424, -0.1558,  0.0461,\n          0.0220, -0.0964,  0.1963,  0.0220, -0.1833, -0.1659, -0.0623,  0.0147,\n          0.1772,  0.1511,  0.0041,  0.1874], grad_fn=<SelectBackward0>))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 六、第5步\n",
    "z_hat = model(X)\n",
    "loss = criterion(z_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "loss, model.linear1.weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，权重在不断更新，损失也在不断降低，达到了使得损失尽可能降低的目标。\n",
    "## 4.开始迭代：batch_size与epoch\n",
    "### 小批量的原因\n",
    "在实现一轮梯度下降之后，只要对梯度下降进行循环，就可以顺利实现迭代多次的梯度下降了。但是在深度学习的世界中，神经网络的训练对象往往是图像、文字、语音、视频等非结构化数据，这些数据的特点之一就是特征张量一般都是大量高维的数据。在深度学习中，如果梯度下降的每次迭代都使用全部数据，将会非常耗费计算资源，且样本量越大，计算开销越高。小批量随机梯度下降（mini-batch stochastic gradient descent，简写为mini-batch SGD）。小批量随机梯度下降的求解与迭代流程与传统梯度下降（GD）基本一致，二者在迭代权重时使用的数据上存在巨大的不同：\n",
    "- 传统梯度下降在每次进行权重迭代（即循环）时都使用全部数据，每次迭代所使用的数据也都一致\n",
    "- mini-batch SGD是每次迭代前都会从整体采样一批固定数目的样本组成批次（batch）B，并用B中的样本进行梯度计算，以减少样本量\n",
    "\n",
    "mini-batch SGD的优势：\n",
    "- 相比传统梯度下降，mini-batch SGD更可能找到全局最小值\n",
    "  ![grad_descent_compare](../assets/grad_descent_compare.png)\n",
    "\n",
    "  传统梯度下降每次迭代时都使用全部数据的梯度下降，所以每次使用的数据是一致的，因此梯度向量的方向和大小都只受到权重w的影响，所以梯度方向的变化相对较小，很多时候看起来梯度甚至是指向一个方向，这样带来的优势是可以使用较大的步长，快速迭代直到找到最小值。但是缺点也很明显，由于梯度方向不容易发生巨大变化，所以一旦在迭代过程中落入局部最优的范围，传统梯度下降就很难跳出局部最优，再去寻找全局最优解了。\n",
    "  而mini-batch SGD在每次迭代前都会随机抽取一批数据，所以每次迭代时带入梯度向量表达式的数据是不同的，梯度的方向同时受到权重和带入的训练数据的影响，因此每次迭代时梯度向量的方向都会发生较大变化。并且，当抽样的数据量越小，本次迭代中使用的样本数据与上一次迭代中使用的样本数据之间的差异就可能越大，这也导致本次迭代中梯度的方向与上一次迭代中梯度的方向有巨大差异。所以对于mini-batch SGD而言，它的梯度下降路线看起来往往是曲折的折线。极端情况下，当每次随机选取的批量中只有一个样本时，梯度下降的迭代轨迹就会变得异常不稳定，这样的梯度下降为随机梯度下降（stochastic gradient descent，SGD）。mini-batch SGD的优势是算法不会轻易陷入局部最优，由于每次梯度向量的方向都会发生巨大变化，因此一旦有机会，算法就能够跳出局部最优，走向全局最优。\n",
    "- mini-batch SGD可以提升神经网络的计算效率，让神经网络计算更快\n",
    "  为了解决计算开销大的问题，可以从全部数据中选出一部分作为全部数据的“近似估计\"，用选出的这一部分数据来进行迭代，每次迭代需要计算的数据量就会更少，计算消耗也会更少，从而提升神经网络的速度。\n",
    "\n",
    "mini-batch SGD存在的问题：**mini-batch使得需要的迭代次数变得不明**。如果最开始就在全局最优的范围内，那可能只需要非常少的迭代次数就收敛，但是如果最开始落入了局部最优的范围，或全局最优与局部最优的差异很小，那可能需要花很长的时间、经过很多次迭代才能够收敛，毕竟不断改变的方向会让迭代的路线变得曲折。\n",
    "### batch_size与epoch\n",
    "在mini-batch SGD中，选择的批量batch含有的样本数被称为batch_size，即批量尺寸，这个尺寸一定是小于数据量的某个正整数值。每次迭代时，需要从数据集中抽取batch_size个数据用于训练。\n",
    "对同样的数据，算法学习得越多，也有应当对数据的状况理解得越深，也就学得越好。然而，并不是对一个数据学习越多越好，毕竟学习得越多，训练时间就越长，同时，收集到的数据只是“样本”，并不能够代表真实世界的客观情况。因此，虽然希望算法对数据了解很深，但也希望算法不要变成”书呆子“，要保留一些灵活性（保留一些**泛化能力**），因此**算法对同样的数据进行学习的次数并不是越多越好**。在mini-batch SGD中，因为每次迭代时都只使用了一小部分数据，所以它迭代的次数并不能代表全体数据一共被学习了多少次，而是用epoch来定义全体数据被学习的次数：一个epoch表示优化算法将全部训练数据都使用了一次，一个epoch包含n次迭代，完成一个epoch所需要的迭代次数$n=\\frac{m}{N}$（其中，m表示样本总数、N表示batch_size）。在深度学习中，常常定义num_epoches作为梯度下降的最外层循环，batch_size作为内层循环，通过使用epoch和batch_size来控制训练的节奏有时候，希望数据被多学习几次，来增加模型对数据的理解；有时候，会控制模型对数据的训练。\n",
    "### TensorDataset与DataLoader\n",
    "要使用小批量随机梯度下降，我们就需要对数据进行采样、分割等操作。在PyTorch中，操作数据所需要使用的模块是torch.utils，utils.data类下面有大量用来执行数据预处理的工具。在小批量梯度下降中，需要将数据划分为许多组特征张量+对应标签的形式，因此最开始要将数据的特征张量与标签打包成一个对象。深度学习中的特征张量维度很少是二维，因此其特征张量与标签几乎总是分开的，不像机器学习中标签常常出现在特征矩阵的最后一列或第一列。合并张量与标签所使用的类是`utils.data.TensorDataset`，这个功能类似于python中的zip，可以将最外面的维度一致的tensor进行打包，也就是将第一个维度一致的tensor进行打包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.284279Z",
     "end_time": "2023-04-07T12:26:17.341331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([500, 2, 3]), torch.Size([500, 3, 4, 5]), torch.Size([500, 1]))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用TensorDataset打包特征张量与标签\n",
    "a = torch.randn(500, 2, 3)  # 三维数据——二维表\n",
    "b = torch.randn(500, 3, 4, 5)  # 四维数据——图像\n",
    "c = torch.randn(500, 1)  # 二维数据——标签\n",
    "a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.313333Z",
     "end_time": "2023-04-07T12:26:17.342331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([2, 3]), torch.Size([3, 4, 5]), torch.Size([1])]\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(a, b, c)  # 合并的条件：被合并的张量的第1个维度的值相等\n",
    "for data in dataset:\n",
    "    print([x.shape for x in data])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们将数据打包成一个对象之后，需要使用划分小批量的类DataLoader：DataLoader是处理训练前专用的功能，它可以接受任意形式的数组、张量作为输入，并将其一次性转换为神经网络可以接入的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.330331Z",
     "end_time": "2023-04-07T12:26:17.357331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x1ed3c590160>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TensorDataset(b, c)\n",
    "loader = DataLoader(\n",
    "    data,  # 数据集\n",
    "    batch_size=64,  # 批大小\n",
    "    shuffle=True,  # 是否打乱数据集，为True时，划分小批量之前随机打乱数据\n",
    "    drop_last=False  # 小批量不能除尽时，是否舍弃最后一个batch\n",
    ")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.364336Z",
     "end_time": "2023-04-07T12:26:17.449373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([52, 3, 4, 5]) torch.Size([52, 1])\n",
      "\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n",
      "torch.Size([64, 3, 4, 5]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# 查看每一个batch的大小，查看drop_last的不同设置：500/64=7...52\n",
    "for data, label in DataLoader(TensorDataset(b, c), batch_size=64, drop_last=False):  # 舍弃最后的除不尽的batch\n",
    "    print(data.shape, label.shape)\n",
    "print()\n",
    "for data, label in DataLoader(TensorDataset(b, c), batch_size=64, drop_last=True):  # 保留最后的除不尽的batch\n",
    "    print(data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.410390Z",
     "end_time": "2023-04-07T12:26:17.451375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(8, 500)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader), len(loader.dataset)  # 查看batch数量、数据集样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.439377Z",
     "end_time": "2023-04-07T12:26:17.467379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.2407, -1.0226, -1.5714,  0.3285,  0.0639],\n          [ 1.2916,  1.6977,  1.3973,  0.8857, -1.3503],\n          [-0.3290, -0.4499,  0.2974,  0.3877,  0.6558],\n          [-1.1717, -2.0272, -0.6773, -0.9697,  0.5789]],\n \n         [[ 0.6247,  0.5819, -0.7018,  0.8464, -1.7277],\n          [-1.0033,  0.7276, -0.1667, -0.1941, -0.6900],\n          [-1.4537,  0.3467,  0.7570,  0.5563,  1.1085],\n          [-0.3636, -0.4727, -1.2861, -0.0556,  0.0434]],\n \n         [[ 1.1056,  1.1036,  0.9601, -1.6370, -0.9004],\n          [ 1.0804,  1.2042,  1.0223, -0.1899,  1.1345],\n          [ 0.6853, -0.2240, -0.8039,  0.5075, -2.3814],\n          [-0.9422,  0.3864,  1.1908, -1.2030,  0.3989]]]),\n tensor([1.1425]))"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader[0] # TypeError: 不能索引DataLoader\n",
    "loader.dataset[0]  # 可以索引Dataset，获取到第1个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.470379Z",
     "end_time": "2023-04-07T12:26:17.513958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看batch_size\n",
    "loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.490375Z",
     "end_time": "2023-04-07T12:26:17.526956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([57, 30]) torch.Size([57])\n"
     ]
    }
   ],
   "source": [
    "# 除了自己生成数据之外，还可以将外部导入的数据放到TensorDataset与DataLoader里使用\n",
    "# 1.导入sk-learn中的数据\n",
    "data = LBC()\n",
    "X = torch.tensor(data.data)\n",
    "y = torch.tensor(data.target)\n",
    "data = TensorDataset(X, y)\n",
    "loader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "for x, y in loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:17.529956Z",
     "end_time": "2023-04-07T12:26:20.075768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((284807, 31),\n    Time        V1        V2        V3        V4        V5        V6        V7  \\\n 0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n 1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n 2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n 3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n 4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n \n          V8        V9  ...       V21       V22       V23       V24       V25  \\\n 0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n 1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n 2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n 3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n 4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n \n         V26       V27       V28  Amount  Class  \n 0 -0.189115  0.133558 -0.021053  149.62      0  \n 1  0.125895 -0.008983  0.014724    2.69      0  \n 2 -0.139097 -0.055353 -0.059752  378.66      0  \n 3 -0.221929  0.062723  0.061458  123.50      0  \n 4  0.502292  0.219422  0.215153   69.99      0  \n \n [5 rows x 31 columns])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.从pandas中导入数据\n",
    "data = pd.read_csv('../data/creditcard.csv')  # 信用卡数据\n",
    "data.shape, data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.081768Z",
     "end_time": "2023-04-07T12:26:20.219449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(557, 284807)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(np.array(data.iloc[:, :-1]), dtype=torch.float32)\n",
    "y = torch.tensor(np.array(data.iloc[:, -1]), dtype=torch.float32)\n",
    "data = TensorDataset(X, y)\n",
    "loader = DataLoader(data, batch_size=512, shuffle=True)\n",
    "len(loader), len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.在MINST-FASHION上实现神经网络的学习流程\n",
    "本次使用的MINST-FASHION数据集是MNIST手写数字数据集的一个改进，包含了10个类别的图像，分别为t-shirt(T恤)、trouser(牛仔裤)、pullover(套衫)、dress(裙子)、coat(外套)、sandal(凉鞋)、shirt(衬衫)、sneaker(运动鞋)、bag(包)和ankle boot(短靴)，直接可以通过torchvision库使用。\n",
    "一个完整的训练流程如下：\n",
    "1. 定义超参数，包括学习率lr、动量值γ、迭代次数epoch、batch_size等，（如果需要）设置初始权重\n",
    "2. 导入数据，将数据切分成batch\n",
    "3. 定义神经网络架构\n",
    "4. 定义损失函数，如果需要的话，将损失函数调整成凸函数，以便求解最小值\n",
    "5. 定义优化器\n",
    "6. 开始在epoch和batch上循环，执行优化算法\n",
    "    1. 调整数据结构，确定数据能够在神经网络、损失函数和优化算法中顺利运行\n",
    "    2. 完成向前传播，计算初始损失\n",
    "    3. 利用反向传播，在损失函数上求解梯度\n",
    "    4. 迭代当前权重\n",
    "    5. 清空本轮梯度\n",
    "    6. 完成模型进度与效果监控\n",
    "7. 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.223449Z",
     "end_time": "2023-04-07T12:26:20.245451Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.设置超参数\n",
    "lr = 0.15\n",
    "gamma = 0.6\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "log_interval = 100  # 日志输出的间隔，以batch为单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.241449Z",
     "end_time": "2023-04-07T12:26:20.330867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset FashionMNIST\n    Number of datapoints: 60000\n    Root location: ../data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.导入数据集\n",
    "mnist = datasets.FashionMNIST(  # 实例化数据\n",
    "    root='../data',  # 存放数据的目录，不包含FashionMNIST本身，没有数据时会下载\n",
    "    download=True,  # 是否下载：数据存在则忽略\n",
    "    train=True,  # 是否用于训练：如果是训练会下载更大的数据集，否则提供小的数据集\n",
    "    transform=transforms.ToTensor()  # 对导入的数据进行统一的处理，对数据集的数值本身进行调整，这里是转换为张量\n",
    ")\n",
    "mnist  # 查看数据的基本情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.334866Z",
     "end_time": "2023-04-07T12:26:20.354866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([60000, 28, 28])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看FashionMNIST数据的特征张量\n",
    "mnist.data.shape  # NHW，分别表示样本量、高、宽，一般还需要加上通道维度，即NHWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.349863Z",
     "end_time": "2023-04-07T12:26:20.360801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 28, 28]), 9)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 索引特征张量与标签\n",
    "mnist[0][0].shape, mnist[0][1]  # mnist[0]：(特征张量, 对应标签)，不需要使用TensorDataset对特征张量和标签进行打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.364802Z",
     "end_time": "2023-04-07T12:26:20.408482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([60000]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看标签\n",
    "mnist.targets.shape, mnist.targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.379802Z",
     "end_time": "2023-04-07T12:26:20.409480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看标签对应的类别名\n",
    "mnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.397482Z",
     "end_time": "2023-04-07T12:26:20.692193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 随机可视化特征张量\n",
    "sample_idx = random.randint(1, mnist.targets.size(0))\n",
    "sample = mnist[sample_idx]\n",
    "plt.imshow(sample[0].squeeze().numpy())\n",
    "plt.title(mnist.classes[sample[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.696195Z",
     "end_time": "2023-04-07T12:26:20.778253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "469"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分mini-batch\n",
    "loader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.712193Z",
     "end_time": "2023-04-07T12:26:20.779251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(784, 10)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.定义神经网络结构\n",
    "# 输入和输出的大小\n",
    "input_size = mnist[0][0].numel()  # 1张图片的元素个数，即输入大小\n",
    "output_size = mnist.targets.unique().size(0)  # 输出大小\n",
    "input_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.731253Z",
     "end_time": "2023-04-07T12:26:20.779251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FashionMNISTModel(\n  (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (linear): Linear(in_features=784, out_features=128, bias=False)\n  (output): Linear(in_features=128, out_features=10, bias=False)\n)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型结构\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self, in_features=10, out_features=2):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.norm = nn.BatchNorm2d(num_features=1)\n",
    "        self.linear = nn.Linear(in_features, 128, bias=False)\n",
    "        self.output = nn.Linear(128, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.norm(x)  # 加入BatchNorm会带来效果提升\n",
    "        x = x.view(-1, self.in_features)  # 调整特征矩阵的结构：-1表示当前维度会根据其他维度的大小自动计算\n",
    "        sigma1 = torch.relu(self.linear(x))\n",
    "        sigma2 = F.log_softmax(self.output(sigma1), dim=-1)\n",
    "        return sigma2\n",
    "\n",
    "\n",
    "# 实例化模型\n",
    "model = FashionMNISTModel(in_features=input_size, out_features=output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T12:26:20.765256Z",
     "end_time": "2023-04-07T12:28:50.762495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:001[ 12800/600000( 2.13%)] Loss: 0.590182 Accuracy: 0.6774\n",
      "Epoch:001[ 25600/600000( 4.27%)] Loss: 0.591718 Accuracy: 0.7374\n",
      "Epoch:001[ 38400/600000( 6.40%)] Loss: 0.452314 Accuracy: 0.7631\n",
      "Epoch:001[ 51200/600000( 8.53%)] Loss: 0.581987 Accuracy: 0.7786\n",
      "Epoch:002[ 72800/600000(12.13%)] Loss: 0.419743 Accuracy: 0.7973\n",
      "Epoch:002[ 85600/600000(14.27%)] Loss: 0.352545 Accuracy: 0.8037\n",
      "Epoch:002[ 98400/600000(16.40%)] Loss: 0.331535 Accuracy: 0.8102\n",
      "Epoch:002[111200/600000(18.53%)] Loss: 0.342344 Accuracy: 0.8152\n",
      "Epoch:003[132800/600000(22.13%)] Loss: 0.246404 Accuracy: 0.8222\n",
      "Epoch:003[145600/600000(24.27%)] Loss: 0.409624 Accuracy: 0.8258\n",
      "Epoch:003[158400/600000(26.40%)] Loss: 0.278721 Accuracy: 0.8292\n",
      "Epoch:003[171200/600000(28.53%)] Loss: 0.297177 Accuracy: 0.8322\n",
      "Epoch:004[192800/600000(32.13%)] Loss: 0.280937 Accuracy: 0.8362\n",
      "Epoch:004[205600/600000(34.27%)] Loss: 0.244004 Accuracy: 0.8385\n",
      "Epoch:004[218400/600000(36.40%)] Loss: 0.361753 Accuracy: 0.8407\n",
      "Epoch:004[231200/600000(38.53%)] Loss: 0.325106 Accuracy: 0.8425\n",
      "Epoch:005[252800/600000(42.13%)] Loss: 0.325068 Accuracy: 0.8456\n",
      "Epoch:005[265600/600000(44.27%)] Loss: 0.307185 Accuracy: 0.8475\n",
      "Epoch:005[278400/600000(46.40%)] Loss: 0.311917 Accuracy: 0.8491\n",
      "Epoch:005[291200/600000(48.53%)] Loss: 0.346331 Accuracy: 0.8503\n",
      "Epoch:006[312800/600000(52.13%)] Loss: 0.308103 Accuracy: 0.8525\n",
      "Epoch:006[325600/600000(54.27%)] Loss: 0.316772 Accuracy: 0.8536\n",
      "Epoch:006[338400/600000(56.40%)] Loss: 0.266991 Accuracy: 0.8548\n",
      "Epoch:006[351200/600000(58.53%)] Loss: 0.275329 Accuracy: 0.8557\n",
      "Epoch:007[372800/600000(62.13%)] Loss: 0.237509 Accuracy: 0.8578\n",
      "Epoch:007[385600/600000(64.27%)] Loss: 0.293765 Accuracy: 0.8587\n",
      "Epoch:007[398400/600000(66.40%)] Loss: 0.314059 Accuracy: 0.8597\n",
      "Epoch:007[411200/600000(68.53%)] Loss: 0.253280 Accuracy: 0.8606\n",
      "Epoch:008[432800/600000(72.13%)] Loss: 0.367892 Accuracy: 0.8621\n",
      "Epoch:008[445600/600000(74.27%)] Loss: 0.362479 Accuracy: 0.8629\n",
      "Epoch:008[458400/600000(76.40%)] Loss: 0.308700 Accuracy: 0.8638\n",
      "Epoch:008[471200/600000(78.53%)] Loss: 0.219979 Accuracy: 0.8647\n",
      "Epoch:009[492800/600000(82.13%)] Loss: 0.215962 Accuracy: 0.8659\n",
      "Epoch:009[505600/600000(84.27%)] Loss: 0.277162 Accuracy: 0.8668\n",
      "Epoch:009[518400/600000(86.40%)] Loss: 0.275433 Accuracy: 0.8675\n",
      "Epoch:009[531200/600000(88.53%)] Loss: 0.190966 Accuracy: 0.8682\n",
      "Epoch:010[552800/600000(92.13%)] Loss: 0.259510 Accuracy: 0.8694\n",
      "Epoch:010[565600/600000(94.27%)] Loss: 0.161849 Accuracy: 0.8700\n",
      "Epoch:010[578400/600000(96.40%)] Loss: 0.315281 Accuracy: 0.8706\n",
      "Epoch:010[591200/600000(98.53%)] Loss: 0.228150 Accuracy: 0.8712\n",
      "Epoch:010[600000/600000(100.00%)] Loss: 0.225845 Accuracy: 0.8716\n"
     ]
    }
   ],
   "source": [
    "# 4.5.定义训练函数：定义损失函数和优化器\n",
    "def fit(model, data_loader, lr=0.01, num_epochs=5, gamma=0):  # 拟合\n",
    "    criterion = nn.NLLLoss()  # 定义损失函数\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=gamma)  # 定义优化器\n",
    "    sample_total = len(data_loader.dataset) * num_epochs\n",
    "    sample_count = 0  # 对样本计数\n",
    "    correct_count = 0  # 对正确样本计数\n",
    "    # 6.在epoch和batch上循环迭代\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "        for iteration, (inputs, labels) in enumerate(data_loader, 1):\n",
    "            # 正向传播\n",
    "            sigma = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(sigma, labels)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            sample_count += labels.size(0)  # 累加样本数\n",
    "            # 获取模型预测标签\n",
    "            _, preds = torch.max(sigma, -1)\n",
    "            correct_count += (preds == labels).sum()  # 累加正确样本数\n",
    "\n",
    "            if iteration % log_interval == 0 or (iteration == len(data_loader) and epoch == num_epochs):\n",
    "                # 7.输出结果\n",
    "                print(\n",
    "                    f'Epoch:{epoch:0>3}[{sample_count:6d}/{sample_total:6d}({sample_count / sample_total:6.2%})] Loss: {loss.item():.6f} Accuracy: {correct_count / sample_count:.4f}')\n",
    "\n",
    "\n",
    "#调用函数开始训练\n",
    "fit(model, loader, lr=lr, num_epochs=num_epochs, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，已经实现了使用真实数据进行模型搭建和训练的完整过程，不使用BatchNorm的效果能够达到87%，加入BatchNorm后模型效果可以提升3%左右，成熟的神经网络架构已经可以在MINST-FASHION数据集上达到99%的精确率，这也是后面进一步努力的方向。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
