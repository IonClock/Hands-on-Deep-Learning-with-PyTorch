{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "@Author   :   Corley Tang\n",
    "@contact  :   cutercorleytd@gmail.com\n",
    "@Github   :   https://github.com/corleytd\n",
    "@Time     :   2023-01-11 19:14\n",
    "@Project  :   Hands-on Deep Learning with PyTorch-tensor_linear_algebra\n",
    "张量的线性代数运算\n",
    "'''\n",
    "\n",
    "# 导入所需的库\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.BLAS和LAPACK概览\n",
    "BLAS（Basic Linear Algeria Subprograms）和LAPACK（Linear Algeria Package）模块提供了完整的线性代数基本方法，函数种类较多，因此此处进行简单分类如下：\n",
    "- **矩阵的形变及特殊矩阵的构造方法**：包括矩阵的转置、对角矩阵的创建、单位矩阵的创建、上/下三角矩阵的创建等\n",
    "- **矩阵的基本运算**：包括矩阵乘法、向量内积、矩阵和向量的乘法等，当然，此处还包含了高维张量的基本运算，将着重探讨矩阵的基本运算拓展至三维张量中的基本方法\n",
    "- **矩阵的线性代数运算**：包括矩阵的迹、矩阵的秩、逆矩阵的求解、伴随矩阵和广义逆矩阵等\n",
    "- **矩阵分解运算**：特征分解和SVD分解（奇异值分解）等\n",
    "\n",
    "矩阵的两种理解方式：\n",
    "- 高维空间中的数据点的集合\n",
    "- 方程组的简写形式\n",
    "\n",
    "## 2.矩阵的形变及特殊矩阵构造方法\n",
    "矩阵的形变方法其实也就是二维张量的形变方法，在实际线性代数运算过程中，经常涉及一些特殊矩阵，如单位矩阵、对角矩阵等。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[83, 86, 80, 28],\n         [91, 59, 75, 69],\n         [55, 93, 35, 30]]),\n tensor([[83, 91, 55],\n         [86, 59, 93],\n         [80, 75, 35],\n         [28, 69, 30]]),\n tensor([[83, 91, 55],\n         [86, 59, 93],\n         [80, 75, 35],\n         [28, 69, 30]]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转置\n",
    "t1 = torch.randint(1, 100, size=(3, 4))\n",
    "t1, torch.t(t1), t1.t()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 单位矩阵\n",
    "torch.eye(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 9,  0,  0,  0,  0],\n         [ 0, 13,  0,  0,  0],\n         [ 0,  0, 10,  0,  0],\n         [ 0,  0,  0,  7,  0],\n         [ 0,  0,  0,  0,  6]]),\n tensor([[ 9,  0,  0,  0,  0],\n         [ 0, 13,  0,  0,  0],\n         [ 0,  0, 10,  0,  0],\n         [ 0,  0,  0,  7,  0],\n         [ 0,  0,  0,  0,  6]]),\n tensor([[ 0,  0,  9,  0,  0,  0,  0],\n         [ 0,  0,  0, 13,  0,  0,  0],\n         [ 0,  0,  0,  0, 10,  0,  0],\n         [ 0,  0,  0,  0,  0,  7,  0],\n         [ 0,  0,  0,  0,  0,  0,  6],\n         [ 0,  0,  0,  0,  0,  0,  0],\n         [ 0,  0,  0,  0,  0,  0,  0]]),\n tensor([[ 0,  0,  0,  0,  0,  0,  0],\n         [ 0,  0,  0,  0,  0,  0,  0],\n         [ 9,  0,  0,  0,  0,  0,  0],\n         [ 0, 13,  0,  0,  0,  0,  0],\n         [ 0,  0, 10,  0,  0,  0,  0],\n         [ 0,  0,  0,  7,  0,  0,  0],\n         [ 0,  0,  0,  0,  6,  0,  0]]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对角矩阵，对角矩阵上移，对角矩阵下移\n",
    "t2 = torch.randint(1, 20, size=(5,))\n",
    "torch.diag(t2), t2.diag(), torch.diag(t2, diagonal=2), torch.diag(t2, -2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[21,  8, 20,  7],\n         [10, 26, 27,  6],\n         [28, 27, 17,  1],\n         [12,  5, 19,  1]]),\n tensor([[21,  8, 20,  7],\n         [ 0, 26, 27,  6],\n         [ 0,  0, 17,  1],\n         [ 0,  0,  0,  1]]),\n tensor([[21,  8, 20,  7],\n         [10, 26, 27,  6],\n         [ 0, 27, 17,  1],\n         [ 0,  0, 19,  1]]),\n tensor([[ 0,  8, 20,  7],\n         [ 0,  0, 27,  6],\n         [ 0,  0,  0,  1],\n         [ 0,  0,  0,  0]]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上三角矩阵，上三角矩阵左下偏移，上三角矩阵右上偏移\n",
    "t3 = torch.randint(1, 30, size=(4, 4))\n",
    "t3, torch.triu(t3), t3.triu(-1), t3.triu(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[21,  8, 20,  7],\n         [10, 26, 27,  6],\n         [28, 27, 17,  1],\n         [12,  5, 19,  1]]),\n tensor([[21,  0,  0,  0],\n         [10, 26,  0,  0],\n         [28, 27, 17,  0],\n         [12,  5, 19,  1]]),\n tensor([[ 0,  0,  0,  0],\n         [10,  0,  0,  0],\n         [28, 27,  0,  0],\n         [12,  5, 19,  0]]),\n tensor([[21,  8,  0,  0],\n         [10, 26, 27,  0],\n         [28, 27, 17,  1],\n         [12,  5, 19,  1]]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下三角矩阵，下三角矩阵左下偏移，下三角矩阵右上偏移\n",
    "t3, torch.tril(t3), torch.tril(t3, -1), t3.tril(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.矩阵的基本运算\n",
    "矩阵不同于普通的二维数组，其具备一定的线性代数含义，而这些特殊的性质，其实就主要体现在矩阵的基本运算上。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(435), tensor(435))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.dot、vdot——点积计算：只能作用于一维张量，且对于数值型对象，二者计算结果并没有区别，两种函数只在进行复数运算时会有区别\n",
    "# torch.dot(t1, t1)  # RuntimeError，只支持一维张量\n",
    "torch.dot(t2, t2), t2.vdot(t2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 4]), torch.Size([4, 4]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.mm——矩阵乘法\n",
    "t1.shape, t3.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5179, 5200, 5874, 1205],\n        [5429, 4632, 5999, 1135],\n        [3425, 3953, 4776, 1008]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "torch.mm(t1, t3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6889, 7396, 6400,  784],\n        [8281, 3481, 5625, 4761],\n        [3025, 8649, 1225,  900]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对应位置相乘\n",
    "t1 * t1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([3148, 3277, 2572]),\n tensor([[3148],\n         [3277],\n         [2572]]),\n tensor([3148, 3277, 2572]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.mv——矩阵和向量相乘：可以看作先将向量转化为列向量再相乘，需要矩阵的列数和向量的元素个数保持相同，应用场景较多，例如线性方程组求解\n",
    "t4 = torch.randint(1, 20, size=(4,))\n",
    "torch.mv(t1, t4), torch.mm(t1, t4.reshape(-1, 1)), torch.mm(t1, t4.reshape(-1, 1)).flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 2, 2]), torch.Size([3, 2, 3]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.bmm——批量矩阵相乘：三维张量的矩阵相乘，是三维张量内部各对应位置的矩阵相乘，需要两个矩阵第一维大小相同、二三维满足矩阵乘法的条件\n",
    "t5 = torch.randint(1, 20, size=(3, 2, 2))\n",
    "t6 = torch.randint(1, 20, size=(3, 2, 3))\n",
    "t5.shape, t6.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 2, 3]),\n tensor([[[334, 194, 394],\n          [340, 188, 292]],\n \n         [[163, 157,  74],\n          [178, 166,  76]],\n \n         [[290, 262, 296],\n          [375, 295, 360]]]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t56_bnn = torch.bmm(t5, t6)\n",
    "t56_bnn.shape, t56_bnn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4]), torch.Size([3, 4]), torch.Size([4, 4]))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.addmm——矩阵相乘再相加\n",
    "t4.shape, t1.shape, t3.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[5191, 5214, 5882, 1216],\n         [5441, 4646, 6007, 1146],\n         [3437, 3967, 4784, 1019]]),\n tensor([[5191, 5214, 5882, 1216],\n         [5441, 4646, 6007, 1146],\n         [3437, 3967, 4784, 1019]]),\n tensor([[15561, 15628, 17638,  3637],\n         [16311, 13924, 18013,  3427],\n         [10299, 11887, 14344,  3046]]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.addmm(t4, t1, t3), t4 + torch.mm(t1, t3), torch.addmm(t4, t1, t3, beta=2, alpha=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[793, 619, 776],\n         [894, 668, 733]]),\n tensor([[793, 619, 776],\n         [894, 668, 733]]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.addbmm——批量矩阵相乘再相加，会对批量相乘后的三维张量第一个维度求和\n",
    "t7 = torch.randint(1, 20, size=(2, 3))\n",
    "torch.addbmm(t7, t5, t6), t7 + torch.bmm(t5, t6).sum(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.矩阵的线性代数运算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(65), tensor(65), tensor(177))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.trace——矩阵的迹：矩阵对角线元素之和，并不一定要求是方阵\n",
    "torch.trace(t3), t3.trace(), t1.trace()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(2), tensor(1))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.rank——矩阵的秩：矩阵中行或列的极大线性无关数，且矩阵中行、列极大无关数总是相同的，任何矩阵的秩都是唯一值，满秩指的是方阵（行数和列数相同的矩阵）中行数、列数和秩相同，满秩矩阵有线性唯一解等重要特性，而其他矩阵也能通过求解秩来降维\n",
    "t8 = torch.tensor([[1., 3], [2, 6]])\n",
    "torch.matrix_rank(t7.to(torch.float)), torch.matrix_rank(t8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(66746.), tensor(-0.))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.det——矩阵的行列式：矩阵的一个基本性质或者属性，通过行列式的计算，可以知道矩阵是否可逆，从而进一步求解矩阵所对应的线性方程，是矩阵进行线性变换的伸缩因子\n",
    "t3 = t3.float()\n",
    "torch.det(t3), t8.det()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.线性方程组的矩阵表达形式——逆矩阵\n",
    "plt.plot(t8[:, 0], t8[:, 1], 'o')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.0288, -0.0381,  0.0284, -0.0017],\n         [-0.0227,  0.0290,  0.0228, -0.0377],\n         [-0.0195,  0.0143, -0.0213,  0.0719],\n         [ 0.1381,  0.0402, -0.0505, -0.1573]]),\n tensor([[ 0.0288, -0.0381,  0.0284, -0.0017],\n         [-0.0227,  0.0290,  0.0228, -0.0377],\n         [-0.0195,  0.0143, -0.0213,  0.0719],\n         [ 0.1381,  0.0402, -0.0505, -0.1573]]))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse函数：逆矩阵\n",
    "t3_inverse = torch.inverse(t3)\n",
    "t3_inverse, t3.inverse()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 1.0000e+00,  0.0000e+00,  2.9802e-08,  2.3842e-07],\n         [-1.1921e-07,  1.0000e+00,  8.9407e-08,  2.3842e-07],\n         [-2.0862e-07, -5.9605e-08,  1.0000e+00,  3.5763e-07],\n         [-8.1956e-08,  0.0000e+00, -5.2154e-08,  1.0000e+00]]),\n tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00, -1.4901e-08],\n         [ 5.9605e-08,  1.0000e+00, -2.2352e-08, -1.4901e-08],\n         [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n         [ 1.1921e-07,  2.0862e-07,  0.0000e+00,  1.0000e+00]]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(t3, t3_inverse), torch.mm(t3_inverse, t3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.3661, -0.1311, -0.0135,  1.5187])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t3 * x = t9 -> x = t3_reverse * t9\n",
    "t9 = torch.randint(1, 20, size=(t3.size(0),), dtype=torch.float)\n",
    "res = torch.mv(t3_inverse, t9)\n",
    "res  # y = res[0] * x1 + res[1] * x2 + res[2] * x3 + res[4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.矩阵的分解\n",
    "矩阵的分解也是矩阵运算中的常规计算，矩阵分解也有很多种类，常见的例如**QR分解**、**LU分解**、**特征分解**、**SVD分解**等等，虽然大多数情况下，矩阵分解都是在形式上将矩阵拆分成几种特殊矩阵的乘积，但本质上，矩阵的分解是去探索矩阵更深层次的一些属性。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.return_types.eig(\n eigenvalues=tensor([[64.2417,  0.0000],\n         [14.9217,  0.0000],\n         [-7.0817,  4.4134],\n         [-7.0817, -4.4134]]),\n eigenvectors=tensor([[-0.4384,  0.6602,  0.0846, -0.1704],\n         [-0.5893, -0.6935,  0.2164, -0.1932],\n         [-0.6032, -0.0239, -0.4340,  0.3352],\n         [-0.3110,  0.2874,  0.7609,  0.0000]])),\n torch.return_types.eig(\n eigenvalues=tensor([[64.2417,  0.0000],\n         [14.9217,  0.0000],\n         [-7.0817,  4.4134],\n         [-7.0817, -4.4134]]),\n eigenvectors=tensor([[-0.4384,  0.6602,  0.0846, -0.1704],\n         [-0.5893, -0.6935,  0.2164, -0.1932],\n         [-0.6032, -0.0239, -0.4340,  0.3352],\n         [-0.3110,  0.2874,  0.7609,  0.0000]])))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.eig——特征分解：A = V * diag(λ) * V-1，只能作用于方阵，输出值分别表示特征值和Q矩阵\n",
    "torch.eig(t3, eigenvectors=True), t3.float().eig(eigenvectors=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.2609,  0.7254, -0.0909, -0.6304],\n         [-0.6536, -0.3113,  0.6650, -0.1836],\n         [-0.6885, -0.1319, -0.6748,  0.2306],\n         [-0.1751,  0.5995,  0.3069,  0.7181]]),\n tensor([1.3195e+02, 2.3625e+01, 1.4831e+01, 3.4246e-07]),\n tensor([[-2.5310e-01,  6.6131e-01, -7.0613e-01,  1.6477e-07],\n         [-2.9214e-01, -1.2077e-01, -8.3913e-03, -9.4868e-01],\n         [-2.8722e-01,  6.4562e-01,  7.0759e-01, -1.9252e-08],\n         [-8.7641e-01, -3.6230e-01, -2.5174e-02,  3.1623e-01]]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.SVD——奇异值分解：A = U Σ VT，U、V是正交矩阵\n",
    "t3[:, -1] = t3[:, 1] * 3\n",
    "u, s, v = torch.svd(t3)\n",
    "u, s, v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.3195e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 2.3625e+01, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 1.4831e+01, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4246e-07]]),\n tensor([[21.0000,  8.0000, 20.0000, 24.0000],\n         [10.0000, 26.0000, 27.0000, 78.0000],\n         [28.0000, 27.0000, 17.0000, 81.0000],\n         [12.0000,  5.0000, 19.0000, 15.0000]]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证SVD\n",
    "torch.diag(s), torch.mm(torch.mm(u, torch.diag(s)), v.t())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[21.0000,  8.0000, 20.0000, 24.0000],\n        [10.0000, 26.0000, 27.0000, 78.0000],\n        [28.0000, 27.0000, 17.0000, 81.0000],\n        [12.0000,  5.0000, 19.0000, 15.0000]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据SVD结果进行降维：4 -> 3\n",
    "u_reduced = u[:, [0, 1, 2]]\n",
    "s_reduced = s[[0, 1, 2]]\n",
    "v_reduced = v[:, [0, 1, 2]].t()\n",
    "torch.mm(u_reduced * s_reduced, v_reduced)  # 得到的新矩阵与原矩阵t3（几乎）一致"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
